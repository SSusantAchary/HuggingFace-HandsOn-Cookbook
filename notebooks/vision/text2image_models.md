# Vision Text-to-Image Model Guide

_Snapshot collected via `https://huggingface.co/api/models?limit=50&pipeline_tag=text-to-image&sort=downloads` (UTC 2025-10-17)._

| Model | Primary uses | Highlights | Considerations | Notebook / Example | Specs |
|---|---|---|---|---|---|
| [stabilityai/sd-turbo](https://huggingface.co/stabilityai/sd-turbo) | Rapid concept art, interactive UX previews, on-device demos | Distilled SDXL delivering ~0.5s 512×512 renders on consumer GPUs; drop-in `StableDiffusionPipeline` | Best quality at 512²; defaults favor speed over detail; add a refiner for print-ready assets | [Diffusers quickstart (SD Turbo)](https://huggingface.co/docs/diffusers/using-diffusers/sd_turbo) | GPU: ≥6GB VRAM; Apple: ≥8GB unified (M1 Pro/Max) |
| [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) | High-fidelity marketing visuals, editorial imagery | 1024×1024 native resolution, strong composition, rich colors; integrates with `StableDiffusionXLPipeline` | Needs ≥8GB VRAM (12GB+ ideal); pair with refiner for photorealism; OpenRail++ usage terms | [Colab: SDXL text-to-image](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/sdxl.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/sdxl.ipynb) | GPU: ≥12GB VRAM; Apple: ≥16GB unified (M2 Pro+) |
| [stable-diffusion-v1-5/stable-diffusion-v1-5](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5) | Legacy fine-tunes, ControlNet workflows, LoRA stacking | Canonical SD 1.5 weights tuned for diffusers; broad ecosystem of LoRAs, embeddings, ControlNets | CreativeML OpenRail-M license; outputs 512² by default; modern UIs may expect original CompVis repo path | [Colab: Stable Diffusion (diffusers)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) | GPU: ≥6GB VRAM; Apple: ≥8GB unified |
| [black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev) | Cinematic key art, stylized portraits, creative direction | Latest Flux architecture with high text adherence and aesthetic quality; supports `FluxPipeline` | Requires diffusers ≥0.31; license restricts certain commercial uses; inference prefers bfloat16 on 24GB GPUs | [Colab: FLUX with CFG](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/flux_with_cfg.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/flux_with_cfg.ipynb) | GPU: ≥24GB VRAM; Apple: ≥32GB unified (M3 Max) |
| [black-forest-labs/FLUX.1-schnell](https://huggingface.co/black-forest-labs/FLUX.1-schnell) | Fast ideation, storyboard thumbnails, real-time prompts | Pruned/quantized Flux variant optimized for speed while retaining style range | Slightly lower detail than `FLUX.1-dev`; Apache-2.0 but check branding guidelines; expect 768² sweet spot | [Colab: FLUX with CFG](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/flux_with_cfg.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/flux_with_cfg.ipynb) | GPU: ≥16GB VRAM; Apple: ≥24GB unified |
| [lightx2v/Qwen-Image-Lightning](https://huggingface.co/lightx2v/Qwen-Image-Lightning) | Multilingual concepting, Chinese/English prompt coverage | Distilled Qwen-Image with Lightning scheduler for ~2–4 steps sampling; strong typography rendering | Actively evolving; check repo for scheduler settings; ensure non-commercial clauses from upstream datasets | [HF Space: Qwen2-Image demo](https://huggingface.co/spaces/Qwen/Qwen2-Image) | GPU: ≥16GB VRAM; Apple: ≥20GB unified (M2 Max) |
| [stabilityai/stable-diffusion-2-1](https://huggingface.co/stabilityai/stable-diffusion-2-1) | Architectural renders, product mockups, SD 2.x research | Improved perspective + negative prompt control vs 1.x; 768² native; solid negative prompt support | Needs new CLIP tokenizer prompts (less meme LoRA support); OpenRail++ obligations; heavier than SD 1.x | [Colab: Stable Diffusion (diffusers)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) | GPU: ≥8GB VRAM; Apple: ≥12GB unified |
| [stabilityai/sdxl-turbo](https://huggingface.co/stabilityai/sdxl-turbo) | Live applications, browser/serverless inference, A/B testing | Turbo distilled SDXL with `EulerAncestralDiscreteScheduler` defaults; works in <4 steps | Trade-off in fine detail; limit to 512–768²; license `other` requires Stability AI brand usage review | [Colab: SDXL Turbo](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/sdxl_turbo.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/pytorch/sdxl_turbo.ipynb) | GPU: ≥8GB VRAM; Apple: ≥12GB unified |
| [CompVis/stable-diffusion-v1-4](https://huggingface.co/CompVis/stable-diffusion-v1-4) | Reproducibility with original papers, academic baselines | Foundational SD 1.4 checkpoint; compatible with legacy scripts and DreamBooth guides | CreativeML OpenRail-M; raw outputs grainier than 1.5; consider safety checker for public apps | [Colab: Stable Diffusion (diffusers)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) [![Google Colab](https://img.shields.io/badge/Google%20Colab-%23F9A825.svg?style=for-the-badge&logo=googlecolab&logoColor=white)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb) | GPU: ≥6GB VRAM; Apple: ≥8GB unified |
| [stabilityai/stable-diffusion-3-medium-diffusers](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers) | Advanced prompting (multi-subject), higher text legibility | SD3 pipeline with flow matching + new text encoder stack; better spelling and scene layout | Needs diffusers ≥0.29 and `StableDiffusion3Pipeline`; license `other`; GPU ≥16GB recommended for 1024² | [Diffusers docs: SD3 pipeline](https://huggingface.co/docs/diffusers/api/pipelines/stable_diffusion_3) | GPU: ≥18GB VRAM (24GB for 1024²); Apple: ≥32GB unified |

**Tip:** For quality vs speed, mix base + refiner (e.g., SDXL base with SDXL refiner) or pair fast models (Turbo/Flux-schnell) with high-quality LoRAs during post-processing.
